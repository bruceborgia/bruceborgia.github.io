1.卷积的特点 
	局部连接 权值共享，下采样
2不同的卷积层都提取什么类型特征
	浅层：提取边缘特征
	中层：提取局部特征
	深层：提取全局特征
3.卷积的size变化
	(h - k + p + s)/s
4.1x1卷积的作用
	1.对特征图的通道数进行升维或降维，降维时减少模型参数量
	2.1x1卷积＋激活函数， 增加网络的非线性，提升网络表达能力
5.转置卷积的作用
	对特征图进行上采样或扩张
		1.语义分割
		2.物体检测中需要输出与原图像大小一致的图
	size： w = s*(n - 1) + k - 2p  (p为单边padding )
6.转置卷积的棋盘效应是什么
	原因： 转置卷积的不均匀叠加导致的图像中某个部位的颜色比其他部分更深
	解决办法： 双线性插值 和 近邻插值
7.空洞卷积的作用
	在不进行池化操作损失信息情况下，增大感受野，让每个卷积输出都包含较大范围的信息
	获取多尺度上下文信息，当带有不同扩展率的空洞卷积核叠加时， 不同感受野会带来多尺度信息
	卷积核size变化：k = k + (k - 1)*(d - 1)
8.感受野的作用
	一般来说感受野越大越好
	感受野足够大时，忽略的信息就较少
	目标检测任务中，设置 的anchor要对其感受野， anchor太大或偏离感受野会对性能产生影响
9.感受野的计算
	RF_n = RF_n-1 + （k - 1）* (stride的乘积)
10.如何增大感受野
	1.使用空洞卷积
	2.使用池化层
	3.增大卷积核
11.简述分组卷积
	1.分组卷积最早出现于alexnet，用于切分网络，使得能够在多个GPU上并行运算
	好处：1-减少参数量
		2-可以堪称稀疏操作，可以在较少的参数量情况下可以获得更好的效果
	缺点：对内存的访问成都并未降低，且现有gpu加速库优化成都有限，因此效率提升的效果并不如理论上
12.简述常见的激活函数， sigmoid， tanh， relu
13.如何提升CNN模型的泛化能力
	1.采集更多数据
	2.优化数据分布，使得数据类别均衡
	3.数据增强
	4.优化网络结构
	5.选用合适优化器
14.BN层是什么，作用是什么，用在哪里， 和layerNorm层归一化的区别
	批量归一化层用在卷积和激活函数之间
	作用：	可以选用较大的学习率，用于加速收敛
		使得分布更稳定
		防止过拟合
		解决梯度消失和梯度爆炸
	区别：
		LN是在同一个样本中不同神经元之间进行归一化，而BN是在同一个batch中不同样本之间的同一位置的神经元之间进行归一化。
		bn是针对小批量，针对特征，计算的均值为小批量数据上的均值和方差， 训练时使用batch均值和方差，测试时使用整个数据集的均值和方差
		layer针对的是单个数据样本，计算的均值和方差是计算单个样本的所有特征的均值和方差 
15.BN层训练时为什么不使用整个数据集的均值和方差
	容易出现过拟合问题 
16.如何解决类别不平衡问题
	1.过采样
	2.欠采样
	3.类别权重，给予少量类的的数据更高的权重
	4.数据增强
17.简述常见的优化器
	1.随机梯度下降SGD
	2.自适应梯度下降 Aaptive
	3.Adam
	SGD缺点是其更新方向完全依赖于当前batch计算出的梯度，因而十分不稳定。

	Adam的优点主要在于：

	考虑历史步中的梯度更新信息，能够降低梯度更新噪声。此外经过偏差校正后，每一次迭代学习率都有个确定范围，使得参数比较平稳。
	但是Adam也有其自身问题：可能会对前期出现的特征过拟合，后期才出现的特征很难纠正前期的拟合效果。二者似乎都没法很好避免局部最优问题。
18.iou是什么，如何计算
	交集/并集
19.目标检测中NMS相关概念和计算
	1.过滤score低于阈值的框
	2.选出概率最大的款
	3.与每个框计算iou，超过阈值则删除
	4.从剩下的候选框中选出score最大的值，重复上述操作
20.one-stage和two-stage的网络有什么区别，都有什么代表的网络
	1.two-stage网络先生成锚框，随后通过卷积网络等进行样本分类， 精读较高，速度较慢 R-CNN, Fast-RCNN，
	2.one-stage 不使用锚框，直接在网络中提取特征来预测物体的位置和分类，速度快， 精度稍低 yolo， ssd
21.提高小目标检测的效果的方法
	1.提高图像分辨率
	2.提高模型的输入分辨率
	3.平铺图像
22.ResNet模型的特点和解决的问题
	将模型的输入加到输出上， 解决随着模型深度加深，梯度变化不明显
23.yolov1的loss是什么，，yolov1的缺点
	1.由于YOLOv1每个网格的检测框只有2个，对于密集型目标检测和小物体检测都不能很好适用。
	2.Inference时，当同一类物体出现的不常见的长宽比时泛化能力偏弱。
	3.由于损失函数的问题，定位误差是影响检测效果的主要原因，尤其是大小物体的处理上，还有待加强。
24.yolov2中采用什么训练方法？多尺度训练的逻辑是什么
	多尺度训练（Multi-Scale Training）的逻辑是模型每训练一定的Epoch，改变输入图片的尺寸，使得模型对不同的输入尺寸更鲁棒，能够从容地对不同尺寸的图像进行检测。图像尺寸使用32的倍数
25.yolov2中loss是什么，
26.yolov2中anchor如何生成
	YOLOv2中引入K-means算法进行anchor的生成，可以自动找到更好的anchor宽高的值用于模型训练的初始化。如果使用经典K-means中的欧氏距离作为度量，意味着较大的Anchor会比较小的Anchor产生更大的误差，聚类结果可能会偏离。
由于目标检测中主要关心anchor与ground true box（gt box）的IOU，不关心两者的大小。因此，使用IOU作为度量更加合适，即提高IOU值。因此YOLOv2采用IOU值为评判标准
27.yolov2 anchor分类器使用什么分类器
28.yolov3引入了基础数据增强技术和高阶数据增强算法，有什么技术
	颜色变换：在色彩通道空间进行数据增强，比如将某种颜色通道关闭，或者改变亮度值。
	旋转变换：选择一个角度，左右旋转图像，可以改变图像内容朝向。
	添加噪声：从高斯等分布中采样出的随机值矩阵加入到图像中。
	锐化和模糊：使用高斯算子，拉普拉斯算子等处理图像。
	缩放变换：图像按照比例进行放大和缩小并不改变图像中的内容。
	平移变换：向上下左右四个维度移动图像。
	翻转变换：关于水平或者竖直的轴进行图像翻转操作。
	裁剪变换：主要有中心裁剪与随机裁剪。
	仿射变换：对图像进行一次线性变换并接上一个平移变换。
29.yolov3分类器使用是什么
Logistic分类器
30.Adam优化器的优势，实现原理，为什么需要偏差纠正
Adam优化器结合了AdaGrad和RMSProp两种优化算法的优点。对梯度的一阶矩估计（First Moment Estimation，即梯	度的均值）和二阶矩估计（Second Moment Estimation，即梯度的未中心化的方差）进行综合考虑，计算出更新步长。
	实现简单，计算高效，对内存需求少。
	参数的更新不受梯度的伸缩变换影响。
	超参数具有很好的解释性，且通常无需调整或仅需很少的微调。
	更新的步长能够被限制在大致的范围内（初始学习率）。
	能自然地实现步长退火过程（自动调整学习率）。
	很适合应用于大规模的数据及参数的场景。
	适用于不稳定目标函数。
	适用于梯度稀疏或梯度存在很大噪声的问题。
	为什么需要偏差纠正： 开始时初始化累计梯度和累计平方梯度初始化为0，梯度的缩放因子会非常大。为了解决这个问题，Adam在计算动量时加入了一个偏差纠正项
31.梯度下降的过程， 优缺点
	1.求梯度
	2.求梯度平均值
	3.更新权重
	优点：算法简介，收敛快，可以很快收敛到局部最优
	缺点：1.对超参数比较敏感， 学习率小了收敛过慢，学习率过大容易越过局部最优点
		2.容易卡在鞍点
		3.平坦区域梯度接近0，算法误判，提前结束迭代，线路局部最小值
	改进：从学习率和梯度方面改进
32.Momentum(带动量的梯度下降) 原理，优缺点
	优点：加速收敛，可以跳出局部最小值，鲁棒性更强
33.Adagrad 自适应学习率优化算法 原理
34.RMSProP 均方根传播原理
35.yolov4 输入端使用什么数据增强
	Masaic 和cutmix
36.Mosaic数据增强技术原理，有什么优点
	CutMix:使用两张图片分别选取部分像素进行拼接，产生新的数据
	Mosaic:使用四张图像采用随机缩放、裁剪和排布的方式进行拼接
	优点：1.优化模型对小目标的检测效果
		2.减少训练算力，由于可以一次性计算4张图片，所以Batchsize不用很大，
		3.让模型的鲁棒性与泛化性能更优
37.yolov4使用csp子模块的作用
CSP子模块主要解决了由于梯度信息重复导致的计算量庞大的问题。
提升模型的学习能力，同时使模型轻量化。
降低计算瓶颈，提高硬件利用率。
降低模型的内存占用。
38.IOU,GIOU,DIOU,CIOU  loss分别是什么 
iou = a交b/ aub
问题：1.bounding box 和ground truth不相交时， iou=0，无法反应两个框离得远近，进而导致iou loss不可导
	2.但两个bounding box 大小相同，iou相同时， iouloss无法区分两者位置
GIOU: 问题：当检测框再ground truth内部切检测款大小一致时， 无法区分相对位置关系
DIOU:问题： 当检测款再ground truth中，DIOU难以优化不同长宽比检测框他们再中心点一致的情况下

39.YOLOV5 有什么改进？ 
自适应图片缩放技术
	1.计算图像尺寸和输入尺寸的缩放比例，获得缩放后的图像尺寸
	2.进行自适应的填充，获得最后的输入图像
Backbone： 使用csp思想
head：引入自适应anchor box 和领域正负样本分配策略
	自适应anchor box： 自适应于训练数据， 根据不同训练数据自动学习适配相应的anchor box
	领域正负样本分配策略：1.将ground truth与当前feature map中的anchor box进行比较，如果ground truth与anchor 	box的宽高比例都处在 ，那么这个ground truth就能与当前featuer map相匹配。
	2、将当前feature map中的ground truth分配给对应的grid cell。将这个grid cell分为四个象限，针对与当前feature 	map匹配的ground truth，会计算该ground truth处于四个象限中的哪一个，并将邻近的两个grid cell中的检测框也作为	正样本。如下图所示，若ground truth偏向于右上角的象限，就会将ground truth所在grid cell的上面和右边的grid cell	中的检测框也作为正样本。
track：1.混合精度训练：尽可能减少精度损失的情况下利用FP16加速训练，并使用FP16存储模型权重，以此减少内存的占用，同时起到加速训练的效果
	2.模型EMA策略：将模型近期不同epoch参数做平均，提高模型整体检测性能以及鲁棒性
40.为什么yolo对小物体不敏感
	对小物体检测不敏感。因为虽然每个cell都可以预测出B个bounding box，
但是在最终只选择 IOU 最高的 bounding box 作为物体检测输出，即：每个 cell
只能预测出一个物体。当物体较小时，所占画面比例较小，比如图像中包含牲畜
群的时候，每个格子 kennel 包含多个物体，但是最后只能检测出其中的一个。
41.为什么yolo一个格子可以检测到大物体
	YOLO 并不是将图片分割成 单独的独立的 网格 分别 输入模型进行预
测，实际上，YOLO 网络最后的卷积层在原图上的感受野是远大于网格大小的，
网格只是用于物体中心位置归属哪个网格的划分
42.常见的边缘检测算子
Roberts算子,Sobel算子，Prewitt算子
43.介绍RCNN到faster rcnn
	1.r-cnn: 1.锚框选择，ROI池化层，将锚框均匀的切分成nxm块，输出每块中的最大值，总是输出nm个值 2。使用预训练模型对每个锚框抽取特征cnn 3.使用svm对类别分类4.训练一个线性回归模型来预测边缘框的偏移
	2.fast RCNN：1.使用cnn对原图抽取特征得到特征图 2. 在原图上选取锚框并将锚框映射到特征图上 3。使用ROI池化层对每个锚框生成固定长度特征
	3.faster RCNN：1.引入RPN模块生成候选框，取代selective search传统锚框生成方法
44.ssd单阶段目标检测算法 ont-stage
45.Fast R-CNN与RCNN在多个方面存在显著的不同，这些差异主要体现在算法流程、特征提取、训练效率以及输出层设计上。以下是对这些差异的详细分析：

1. 算法流程
RCNN：RCNN的算法流程较为复杂，主要包括四个步骤：首先通过选择性搜索（Selective Search）方法从图像中生成大量的候选区域（Region Proposals）；然后对每个候选区域使用CNN进行特征提取；接着使用SVM分类器对提取的特征进行分类；最后通过边界框回归（Bounding Box Regression）对候选框的位置进行精细调整。
Fast R-CNN：相比之下，Fast R-CNN的算法流程更为简洁和高效。它首先对整个输入图像进行卷积操作，得到特征图（Feature Map）；然后使用选择性搜索方法在原始图像上生成候选区域，并将这些候选区域映射到特征图上；接着对每个候选区域使用ROI Pooling层进行特征池化，得到固定大小的特征向量；最后通过两个并行的全连接层（一个用于分类，一个用于边界框回归）同时完成分类和回归任务。
2. 特征提取
RCNN：在RCNN中，每个候选区域都需要独立地通过CNN进行特征提取，这导致大量的重复计算，尤其是在候选区域重叠较多的情况下。
Fast R-CNN：Fast R-CNN通过只对整张图像进行一次卷积操作，然后在特征图上对候选区域进行特征池化，从而避免了重复计算，大大提高了特征提取的效率。
3. 训练效率
RCNN：RCNN的训练过程是多阶段的，包括微调CNN、训练SVM分类器和训练边界框回归器，这些阶段需要分别进行，且需要存储大量的中间特征，导致训练过程既耗时又占用大量磁盘空间。
Fast R-CNN：Fast R-CNN的训练过程是单阶段的，它使用多任务损失函数（Multi-task Loss）同时优化分类和回归任务，这不仅简化了训练流程，还提高了训练效率。此外，由于Fast R-CNN不需要存储中间特征，因此也节省了磁盘空间。
4. 输出层设计
RCNN：RCNN的输出层是独立的，分别用于分类和边界框回归。
Fast R-CNN：Fast R-CNN的输出层是两个并行的全连接层，一个用于分类（输出每个类别的概率），另一个用于边界框回归（输出边界框的平移和缩放参数）。这种设计使得Fast R-CNN能够同时完成分类和回归任务，提高了算法的整体性能。
综上所述，Fast R-CNN相比RCNN在算法流程、特征提取、训练效率以及输出层设计等方面都进行了显著的改进和优化，从而实现了更高的检测精度和更快的检测速度。

46.梯度爆炸和消失的原因，解决方案
梯度爆炸和梯度消失问题都是因为网络太深，网络权重更新不稳定造成的，本质上是梯度方向传播的连乘效应。

梯度爆炸和梯度消失的解决方法

1. 使用预训练加微调策略。
2. 进行梯度截断。
3. 使用ReLU、LeakyReLU等激活函数。
4. 引入BN层。
5. 使用残差结构。
6. 使用LSTM思想
46.如何解决过拟合
	1.数据增强
	2. early stopping
	3.dropout
	4.l1, l2正则化
47.FPN, PAN, SPP区别
FPN:特征金字塔
pan：在FPN的自上而下形成的特征金字塔的基础上，来以下这波操作就是PAN啦

（1）先复制特征金字塔中最底下的那层（①），变成新特征金字塔的最底层。

（2）将新特征金字塔的最底层来一个下采样操作，然后原特征金字塔的倒数第二层进行一个3 * 3卷积，步幅为2；然后与下采样后的最底层进行一个横向连接，两者相加。最后再来一个3 * 3卷积来融合他们的特征。

（3）新特征金字塔其他层的操作与（2）一致。
spp：三个平行得maxpool， 随后和输入concat起来
增加感受野，更能获取多尺度特征，训练速度也让人满意

48.CSP模块解决了三个方面的问题：
解决梯度信息重复导致计算量过大问题
提升模型的学习能力，同时使模型轻量化。
降低计算瓶颈，提高硬件利用率。
降低模型的内存占用

49.dropout原理， 训练和测试过程中都需要dropout吗？

以一定概率丢弃神经元

训练过程中需要dropout， 测试过程中不需要
50.LSTM的核心要点总结：

基本结构：
LSTM通过引入“记忆单元”（cell state）和三个“门”机制（输入门、遗忘门、输出门）来控制信息的流动和保留：
遗忘门（Forget Gate）：决定丢弃哪些过时信息。
输入门（Input Gate）：控制当前输入中哪些信息需要加入记忆单元。
输出门（Output Gate）：决定当前时间步的输出内容。
工作原理：
记忆单元贯穿整个网络，允许信息长期传递。
门机制使用sigmoid和tanh激活函数，调节信息流，保留重要信息，遗忘无关信息。

51.门控循环单元（GRU，Gated Recurrent Unit）是一种改进的循环神经网络（RNN）变体，与LSTM类似，旨在解决传统RNN的长序列依赖问题和梯度消失问题，但结构更简单高效。以下是GRU的核心要点总结：

基本结构：
GRU通过两个“门”机制控制信息的流动：
更新门（Update Gate）：决定当前时间步保留多少过去信息，并加入多少新信息。
重置门（Reset Gate）：控制前一时间步的状态对当前候选状态的影响程度。
工作原理：
没有独立的记忆单元（如LSTM的cell state），而是直接用隐藏状态（hidden state）传递信息。
更新门和重置门通过sigmoid函数调节信息，候选状态通过tanh函数计算，最终融合过去和当前信息。
优点：
相比LSTM，GRU参数更少，计算效率更高，训练速度更快。
在许多任务中性能接近LSTM，但在资源有限时更实用。
依然能捕捉序列中的依赖关系。
52.DETR和ViT的区别

DETR（Detection Transformer）和ViT（Vision Transformer）是两种基于Transformer的深度学习模型，分别用于目标检测和图像分类任务。尽管它们都利用了Transformer架构，但在处理方式和应用场景上有显著的区别。

ViT（Vision Transformer）

ViT的主要目标是将图像分类任务转化为序列数据处理。具体步骤如下：

图像分块：将输入图像划分为固定大小的块（例如16x16像素）。

序列化：将这些图像块展平并映射为Transformer所需的输入向量。

位置编码：为每个图像块添加位置编码，以保留其在原图像中的位置信息。

Transformer处理：将这些序列化的图像块输入到Transformer编码器中进行处理。

分类：使用常规的多分类方法对Transformer的输出进行分类


DETR（Detection Transformer）

DETR的主要目标是实现端到端的目标检测，避免传统目标检测中的后处理步骤。具体步骤如下：

特征提取：使用CNN提取图像特征，并将其映射为固定大小的向量。

位置编码：为特征向量添加位置编码。

Transformer处理：将特征向量输入到Transformer编码器中，学习图像的全局信息。

预测框生成：使用可学习的查询向量作为输入，通过Transformer解码器生成预测框。

匹配与优化：通过匈牙利算法匹配预测框和真实框，并计算损失进行模型优化

主要区别

任务焦点： ViT：主要用于图像分类任务，将图像块序列化后输入Transformer进行分类。 DETR：专注于目标检测任务，直接预测物体的边界框和类别。

架构设计： ViT：直接将图像块作为序列输入到Transformer编码器中，位置编码用于保留空间信息。 DETR：具有特定的编码器-解码器设计，用于集合预测和目标检测。

输出和后处理： ViT：输出是图像分类的类别概率。 DETR：输出是物体的集合，不需要NMS后处理。

计算复杂度： ViT：通过减少序列长度来降低计算复杂度。 DETR：通过集合预测减少输出数量^1^^2^。